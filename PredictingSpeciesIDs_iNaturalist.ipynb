{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\",999)\n",
    "from pandas.io.json import json_normalize\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Page 0\n",
      "Downloading Page 1\n",
      "Downloading Page 2\n",
      "Downloading Page 3\n",
      "Downloading Page 4\n",
      "Downloading Page 5\n",
      "Downloading Page 6\n",
      "Downloading Page 7\n",
      "Downloading Page 8\n",
      "Downloading Page 9\n",
      "Downloading Page 10\n",
      "Downloading Page 11\n",
      "Downloading Page 12\n",
      "Downloading Page 13\n",
      "Downloading Page 14\n",
      "Downloading Page 15\n",
      "Downloading Page 16\n",
      "Downloading Page 17\n",
      "Downloading Page 18\n",
      "Downloading Page 19\n",
      "Downloading Page 20\n",
      "Downloading Page 21\n",
      "Downloading Page 22\n",
      "Downloading Page 23\n",
      "Downloading Page 24\n",
      "Downloading Page 25\n",
      "Downloading Page 26\n",
      "Downloading Page 27\n",
      "Downloading Page 28\n",
      "Downloading Page 29\n",
      "Downloading Page 30\n",
      "Downloading Page 31\n",
      "Downloading Page 32\n"
     ]
    }
   ],
   "source": [
    "#number per page = 30 \n",
    "total_records = 1000\n",
    "per_page = 30\n",
    "n=int(total_records/per_page)\n",
    "alldata =[]    \n",
    "#loop to get all pages (n) (API only allows a max of 100 enteries per page)\n",
    "for i in xrange(0, n):\n",
    "    try:\n",
    "        print \"Downloading Page {}\".format(i)\n",
    "        api ='http://api.inaturalist.org/v1/observations?page={}&quality_grade=any&identifications=any&captive=false&iconic_taxa%5B%5D=Animalia&place_id=14'.format(i)\n",
    "        req = urllib2.Request(api)\n",
    "        response = urllib2.urlopen(req)\n",
    "        response_read = response.read()\n",
    "        json_data=json.loads(response_read)\n",
    "        df = json_normalize(json_data, 'results', meta = ['page','per_page','total_results'])\n",
    "        alldata.append(df)\n",
    "    except:\n",
    "        pass  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(alldata, open(\"inat_pickle.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iNat_df = pd.concat(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 68)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iNat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_del = ['annotations','comments','faves','flags','ofvs','outlinks','project_ids',\n",
    "                  'project_ids_with_curator_id','project_ids_without_curator_id','project_observations',\n",
    "                  'observation_photos',\n",
    "                 'quality_metrics','sounds','tags','votes','non_owner_ids']\n",
    "iNat_df.drop(columns_to_del,axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iNat_numpy= iNat_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iNat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iNat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('iNat_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkdf = sqlsc.createDataFrame(iNat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cached_votes_total: long (nullable = true)\n",
      " |-- captive: boolean (nullable = true)\n",
      " |-- comments_count: long (nullable = true)\n",
      " |-- community_taxon_id: double (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- created_at_details: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: long (valueContainsNull = true)\n",
      " |-- created_time_zone: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- faves_count: long (nullable = true)\n",
      " |-- geojson: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- geoprivacy: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- id_please: boolean (nullable = true)\n",
      " |-- identifications: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- identifications_count: long (nullable = true)\n",
      " |-- identifications_most_agree: boolean (nullable = true)\n",
      " |-- identifications_most_disagree: boolean (nullable = true)\n",
      " |-- identifications_some_agree: boolean (nullable = true)\n",
      " |-- license_code: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- map_scale: double (nullable = true)\n",
      " |-- mappable: boolean (nullable = true)\n",
      " |-- num_identification_agreements: long (nullable = true)\n",
      " |-- num_identification_disagreements: long (nullable = true)\n",
      " |-- oauth_application_id: double (nullable = true)\n",
      " |-- obscured: boolean (nullable = true)\n",
      " |-- observed_on: string (nullable = true)\n",
      " |-- observed_on_details: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: long (valueContainsNull = true)\n",
      " |-- observed_on_string: string (nullable = true)\n",
      " |-- observed_time_zone: string (nullable = true)\n",
      " |-- out_of_range: boolean (nullable = true)\n",
      " |-- owners_identification_from_vision: boolean (nullable = true)\n",
      " |-- photos: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- place_guess: string (nullable = true)\n",
      " |-- place_ids: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- positional_accuracy: double (nullable = true)\n",
      " |-- preferences: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: boolean (valueContainsNull = true)\n",
      " |-- public_positional_accuracy: double (nullable = true)\n",
      " |-- quality_grade: string (nullable = true)\n",
      " |-- reviewed_by: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- site_id: long (nullable = true)\n",
      " |-- species_guess: string (nullable = true)\n",
      " |-- taxon: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: map (valueContainsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- time_observed_at: string (nullable = true)\n",
      " |-- time_zone_offset: string (nullable = true)\n",
      " |-- updated_at: string (nullable = true)\n",
      " |-- uri: string (nullable = true)\n",
      " |-- user: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- uuid: string (nullable = true)\n",
      " |-- total_results: long (nullable = true)\n",
      " |-- per_page: long (nullable = true)\n",
      " |-- page: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sparkdf.species_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparkdf.groupby(data['species_guess']).max().show()\n",
    "sparkdf.registerTempTable(\"results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|quality_grade|\n",
      "+-------------+\n",
      "|     research|\n",
      "|       casual|\n",
      "|     needs_id|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlsc.sql(\"select distinct quality_grade from results\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenColumn(df, column_list):\n",
    "    for column in column_list:\n",
    "        flat_columns = df[column].apply(pd.Series)\n",
    "        flat_columns.columns = [column+'_'+str(flat_column_name) for flat_column_name in list(flat_columns.columns)]\n",
    "        df= df.drop(column, 1).merge(flat_columns, left_index=True, right_index=True)\n",
    "    return df\n",
    "column_list = ['created_at_details','geojson','identifications','observation_photos',\n",
    "               'observed_on_details','photos', 'place_ids','taxon','user']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
